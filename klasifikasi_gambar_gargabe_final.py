# -*- coding: utf-8 -*-
"""Klasifikasi Gambar_Gargabe_FInal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nHBGvqNgyTRICL8a3FU8DcF55GccY0k2

# Proyek Klasifikasi Gambar: [[Garbage Classification](https://www.kaggle.com/datasets/mostafaabla/garbage-classification)]
- **Nama:** Ch Angga Marcelio
- **Email:** chmarcel0603@gmail.com
- **ID Dicoding:** MC315D5Y1131

## Import Semua Packages/Library yang Digunakan
"""

# Commented out IPython magic to ensure Python compatibility.
# Mengimpor libraries umum yang sering digunakan
import os, shutil
import zipfile
import random
from random import sample
import shutil
from shutil import copyfile
import pathlib
from pathlib import Path
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm as tq

# Mengimpor libraries untuk visualisasi
# %matplotlib inline
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.image import imread

# Mengimpor libraries untuk pemrosesan data gambar
import cv2
from PIL import Image
import skimage
from skimage import io
from skimage.transform import resize
from skimage.transform import rotate, AffineTransform, warp
from skimage import img_as_ubyte
from skimage.exposure import adjust_gamma
from skimage.util import random_noise

# Mengimpor libraries untuk pembuatan dan evaluasi model
import keras
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras import Model, layers
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.layers import InputLayer, Conv2D, SeparableConv2D, MaxPooling2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.densenet import DenseNet121
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau

# Mengabaikan peringatan
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# Mencetak versi TensorFlow yang sedang digunakan
print(tf.__version__)

"""## Data Preparation

### Data Loading
"""

from google.colab import drive
drive.mount('/content/drive')

data_dir = "/content/drive/MyDrive/Colab Notebooks/garbage"

"""### Data Preprocessing"""

classes = os.listdir(data_dir)
print("Kelas sampah yang tersedia:", classes)

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(256, 256),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(256, 256),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

def count_images_per_class(data_dir):
    class_counts = {}
    for class_name in os.listdir(data_dir):
        class_path = os.path.join(data_dir, class_name)
        if os.path.isdir(class_path):
            count = len([file for file in os.listdir(class_path) if file.lower().endswith(('.jpg', '.jpeg', '.png'))])
            class_counts[class_name] = count
    return class_counts

counts = count_images_per_class(data_dir)
for class_name, count in counts.items():
    print(class_name, ":", count)

# Dapatkan daftar kelas
classes = sorted(os.listdir(data_dir))
num_classes = len(classes)

# Setup plot
plt.figure(figsize=(15, 10))

# Loop melalui setiap kelas
for i, class_name in enumerate(classes):
    # Dapatkan path ke gambar pertama di setiap kelas
    class_path = os.path.join(data_dir, class_name)
    img_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    if not img_files:
        print(f"Tidak ada gambar ditemukan di kelas {class_name}")
        continue

    img_path = os.path.join(class_path, img_files[0])  # Ambil gambar pertama

    try:
        # Load gambar dengan preprocessing yang sama seperti model
        img = image.load_img(img_path, target_size=(224, 224))
        img_array = image.img_to_array(img)
        img_array = img_array / 255.0  # Normalisasi

        plt.subplot(3, 4, i+1)
        plt.imshow(img_array)
        plt.title(class_name)
        plt.axis('off')
    except Exception as e:
        print(f"Gagal memuat gambar {img_path}: {str(e)}")

plt.tight_layout()
plt.show()

# Daftar kelas yang ingin dipilih
selected_classes = ['paper', 'glass', 'cardboard', 'metal', 'plastic', 'white-glass', 'trash', 'shoes', 'clothes']

# List untuk menyimpan path dan label
img_paths = []
labels = []

# Karena kamu hanya punya satu direktori (bukan list), maka kita hanya iterasi dari situ
for class_name in os.listdir(data_dir):
    if class_name in selected_classes:
        class_path = os.path.join(data_dir, class_name)
        for img_name in os.listdir(class_path):
            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(class_path, img_name)
                img_paths.append(img_path)
                label = 'glass' if class_name == 'white-glass' else class_name
                labels.append(label)

# Buat dataframe
df = pd.DataFrame({
    'imgPath': img_paths,
    'label': labels
})

# Acak data
df = df.sample(frac=1).reset_index(drop=True)

# Tampilkan hasilnya
df.head()

# Fungsi untuk membagi DataFrame dengan rasio tertentu untuk setiap kelas
def DataFrameSpliting(df, ratio, classesList):
    trainDf = pd.DataFrame(columns=['imgPath', 'label'])
    testDf = pd.DataFrame(columns=['imgPath', 'label'])

    for clas in classesList:
        tempDf = df[df['label'] == clas].sample(frac=1).reset_index(drop=True)
        split_index = int(len(tempDf) * ratio)
        trainClassDf = tempDf[:split_index]     # 85% training
        testClassDf = tempDf[split_index:]      # 15% testing

        trainDf = pd.concat([trainDf, trainClassDf], axis=0)
        testDf = pd.concat([testDf, testClassDf], axis=0)

    # Final shuffle and reset index
    return trainDf.sample(frac=1).reset_index(drop=True), testDf.sample(frac=1).reset_index(drop=True)

# Daftar kelas dari label yang ada
classList = df['label'].unique().tolist()

# Lakukan splitting
trainDf, testDf = DataFrameSpliting(df, 0.85, classList)

# Cek hasil
print("Jumlah data train:", len(trainDf))
print("Jumlah data test:", len(testDf))
trainDf.head()

trainDf

trainDf['label'].value_counts()

"""#### Split Dataset"""

datagenTrain = ImageDataGenerator(
            rescale=1./255,
            zoom_range=(1.0, 1.2),
            horizontal_flip=True,
            vertical_flip=True,
            rotation_range=45,
)

IMG_SIZE = (224,224)

trainGenerator = datagenTrain.flow_from_dataframe(
    trainDf ,
    x_col='imgPath',
    y_col='label',
    target_size=IMG_SIZE,
    batch_size=64 ,
    class_mode='categorical'
)


datagenTest = ImageDataGenerator( rescale=1./255 )

testGenerator = datagenTest.flow_from_dataframe(
    testDf ,
    x_col='imgPath',
    y_col='label',
    target_size=IMG_SIZE,
    batch_size=8 ,
    class_mode='categorical',
    shuffle=False
)


print(f"Training set size: {trainGenerator.samples}")
print(f"Testing set size: {testGenerator.samples}")

"""## Modelling"""

with tf.device('/GPU:0'):  # To use GPU
    model = Sequential([
        MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),
        Flatten(),
        Dense(64, activation='relu'),
        BatchNormalization(),
        Dropout(0.08),
        Dense(8, activation='softmax')
    ])

preTrainedModel = model.layers[0]
for layer in preTrainedModel.layers[:-4]:
    layer.trainable = False

model.compile(optimizer='adam',loss='categorical_crossentropy' ,metrics=['accuracy'])

class StopAt95Accuracy(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if logs.get('val_accuracy') is not None:
            val_acc = logs['val_accuracy']
            if val_acc >= 0.95:
                print(f"\nVal accuracy {val_acc:.4f} reached 95%, stopping training.")
                self.model.stop_training = True

history = model.fit(
    trainGenerator,
    validation_data=testGenerator,
    epochs=30,
    verbose=1,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            patience=4,
            monitor='val_accuracy',
            restore_best_weights=True
        ),
        StopAt95Accuracy()
    ]
)

model.summary()

"""## Evaluasi dan Visualisasi"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

predictions = model.predict(testGenerator)

trainGenerator.class_indices

test_loss, test_accuracy = model.evaluate(testGenerator)
test_accuracy

trueClasses = testGenerator.classes
trueClasses[:10]

predictedClasses = predictions.argmax(axis=-1)
predictedClasses[:10]

ClassificationReport = classification_report(trueClasses, predictedClasses)
print('Classification Report: \n', ClassificationReport )

images = []
predictedClasses = []
trueClasses = []


class_labels = list(testGenerator.class_indices.keys())

for i in range(len(testGenerator)):
    img_batch, true_labels_batch = next(testGenerator)
    true_class_idx = np.argmax(true_labels_batch[0])

    prediction = model.predict(img_batch)
    predicted_class_idx = np.argmax(prediction[0])

    predicted_class = class_labels[predicted_class_idx]
    true_class = class_labels[true_class_idx]

    images.append(np.squeeze(img_batch[0]))
    predictedClasses.append(predicted_class)
    trueClasses.append(true_class)

    if i >= 20:
        break

fig, axs = plt.subplots(4, 5, figsize=(25, 10))


axs = axs.flatten()

for ax,img , pred , true in zip(axs , images , predictedClasses , trueClasses):
    ax.imshow(img)
    ax.set_title(f"Pred: {pred}, True: {true}" ,fontsize=14)
    ax.axis('off')

plt.tight_layout()
plt.show()

"""## Konversi Model"""

#Simpan Model
os.makedirs('submission/tfjs_model', exist_ok=True)
os.makedirs('submission/tflite', exist_ok=True)
os.makedirs('submission/saved_model', exist_ok=True)

# Simpan ke SavedModel
model.export('submission/saved_model/garbage_classifier')

converter = tf.lite.TFLiteConverter.from_saved_model('submission/saved_model/garbage_classifier')
tflite_model = converter.convert()

with open('submission/tflite/model.tflite', 'wb') as f:
    f.write(tflite_model)

with open('submission/tflite/label.txt', 'w') as f:
    f.write('\n'.join(train_generator.class_indices.keys()))

import tensorflowjs as tfjs

tfjs.converters.convert_tf_saved_model(
    'submission/saved_model/garbage_classifier',
    'submission/tfjs_model'
)